defmodule UScore.Users do
  @moduledoc """
  Functions for dealing with User resources
  """

  import Ecto.Query
  alias UScore.Repo
  alias UScore.Users.{PointsRandomizer, User}

  @clock Application.compile_env!(:uscore, :clock)
  @db_pool_size Application.compile_env!(:uscore, Repo)[:pool_size]
  @update_batch_size 1_000

  @doc """
  Regenerates all Users 'points' randomly assigning a number generated by the database
  random function.

    * Users are updated in batches of ids range.
    * Updates are made concurrently using Task.async_stream/2.

  """
  def regenerate_points do
    metadata = fetch_table_metadata()
    date_now = current_date_time()

    build_ids_ranges(metadata.min_id, metadata.max_id, @update_batch_size)
    |> Task.async_stream(&update_users_in_range(&1, date_now), max_concurrency: @db_pool_size)
    |> Stream.run()
  end

  defp fetch_table_metadata do
    query = from u in User, select: %{min_id: min(u.id), max_id: max(u.id), count: count()}
    Repo.one(query)
  end

  defp build_ids_ranges(min_id, max_id, batch_size) do
    min_id
    |> Stream.iterate(&(&1 + batch_size))
    |> Stream.take_while(&(&1 < max_id))
    |> Stream.concat([max_id])
    |> Stream.chunk_every(2, 1, :discard)
  end

  defp update_users_in_range([start_id, end_id], date_now) do
    subquery =
      from(us in User,
        select: %{
          id: us.id,
          points: fragment("floor(random() * ?)::integer", ^PointsRandomizer.uniq_points_count())
        },
        where: us.id >= ^start_id,
        where: us.id <= ^end_id
      )

    update_users_query =
      from(
        u in User,
        join: us in subquery(subquery),
        where: u.id == us.id,
        update: [
          set: [
            points: us.points,
            inserted_at: ^date_now,
            updated_at: ^date_now
          ]
        ]
      )

    Repo.update_all(update_users_query, [])
  end

  defp current_date_time do
    @clock.utc_now()
    |> DateTime.to_naive()
    |> NaiveDateTime.truncate(:second)
  end
end
